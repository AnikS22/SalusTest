"""
SmolVLA Ensemble Wrapper with Signal Extraction for SALUS
File: salus/core/vla/wrapper.py

SmolVLA-450M model ensemble for epistemic uncertainty estimation
and safety signal extraction.
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, Tuple, Optional, List
import numpy as np
from pathlib import Path


class SmolVLAEnsemble(nn.Module):
    """
    Ensemble of SmolVLA-450M models for epistemic uncertainty estimation.
    Runs 5 models in parallel on single GPU.
    """

    def __init__(
        self,
        model_path: str = "~/models/smolvla/smolvla_base",
        ensemble_size: int = 5,
        device: str = "cuda:0"
    ):
        super().__init__()

        self.device = torch.device(device)
        self.ensemble_size = ensemble_size
        self.model_path = Path(model_path).expanduser()

        print(f"\nü§ñ Loading SmolVLA ensemble ({ensemble_size} models on {device})...")

        # Import SmolVLA from lerobot
        try:
            from lerobot.policies.smolvla.modeling_smolvla import SmolVLAPolicy
        except ImportError as e:
            raise ImportError(
                f"SmolVLA not found. Install lerobot: pip install lerobot\nOriginal error: {e}"
            )

        # Load ensemble
        # For diversity, we could fine-tune with different seeds, but for now
        # we'll use the same pre-trained model (diversity comes from dropout)
        self.models = nn.ModuleList()
        for i in range(ensemble_size):
            print(f"  Loading model {i+1}/{ensemble_size}...")

            # Force single GPU by limiting visible devices
            import os
            original_cuda_visible = os.environ.get('CUDA_VISIBLE_DEVICES', None)
            if 'cuda' in str(self.device):
                device_id = str(self.device).split(':')[-1]
                # Set so only this GPU is visible (will appear as cuda:0 to the model)
                os.environ['CUDA_VISIBLE_DEVICES'] = device_id

            # Load model (will go to cuda:0 which is our target device)
            model = SmolVLAPolicy.from_pretrained(str(self.model_path))

            # Restore original CUDA_VISIBLE_DEVICES
            if original_cuda_visible is not None:
                os.environ['CUDA_VISIBLE_DEVICES'] = original_cuda_visible
            elif 'CUDA_VISIBLE_DEVICES' in os.environ:
                del os.environ['CUDA_VISIBLE_DEVICES']

            # Now explicitly move to target device
            model = model.to(self.device)

            model.eval()  # Evaluation mode (but we'll enable dropout for diversity)
            self.models.append(model)
            print(f"  ‚úì Model {i+1}/{ensemble_size} loaded")

        print(f"‚úÖ SmolVLA ensemble ready on {device}")
        print(f"   Model size: ~450M parameters per model")
        print(f"   Total VRAM: ~{0.9 * ensemble_size:.1f}GB (approximate)")

        # Enhanced signal extractor with VLA internals
        self.signal_extractor = EnhancedSignalExtractor(device=self.device)

        # Load tokenizer for text preprocessing
        try:
            from transformers import AutoTokenizer
            # SmolVLM2 uses Qwen2 tokenizer
            self.tokenizer = AutoTokenizer.from_pretrained("HuggingFaceTB/SmolVLM2-500M-Video-Instruct")
            print(f"   ‚úÖ Tokenizer loaded")
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Failed to load tokenizer: {e}")
            self.tokenizer = None

    @torch.no_grad()
    def forward(
        self,
        observation: Dict[str, torch.Tensor],
        return_internals: bool = True
    ) -> Dict:
        """
        Forward pass through ensemble.

        Args:
            observation: Dict with keys:
                - 'image': (B, C, H, W) - camera image(s)
                - 'state': (B, state_dim) - robot proprioception
                Optional:
                - 'wrist_image': (B, C, H, W) - wrist camera
            return_internals: Whether to return internal activations

        Returns:
            action_mean: (B, action_dim) - mean action across ensemble
            action_var: (B, action_dim) - variance (epistemic uncertainty)
            internals: dict of internal activations (if requested)
        """

        # Ensure inputs are on correct device
        observation = {k: v.to(self.device) if isinstance(v, torch.Tensor) else v
                       for k, v in observation.items()}

        # Preprocess text task into language tokens
        if 'task' in observation and 'observation.language.tokens' not in observation:
            task_text = observation['task']
            if isinstance(task_text, list):
                task_text = task_text[0]  # Take first task if batched

            # Tokenize text
            if self.tokenizer is not None:
                tokens = self.tokenizer(
                    task_text,
                    return_tensors="pt",
                    padding=True,
                    truncation=True,
                    max_length=512
                )
                observation['observation.language.tokens'] = tokens['input_ids'].to(self.device)
                # Convert attention mask to boolean
                observation['observation.language.attention_mask'] = tokens['attention_mask'].bool().to(self.device)
            else:
                # Fallback: create dummy tokens
                observation['observation.language.tokens'] = torch.zeros((1, 10), dtype=torch.long, device=self.device)
                observation['observation.language.attention_mask'] = torch.ones((1, 10), dtype=torch.bool, device=self.device)

        # Collect actions and internals from all models
        actions = []
        all_internals = []
        hidden_states = []  # VLA internal representations

        for i, model in enumerate(self.models):
            # Enable dropout for diversity even in eval mode
            model.train()  # Enables dropout

            # Forward pass
            # SmolVLA expects observation dict
            output = model.select_action(observation)

            # Extract action
            if isinstance(output, dict):
                action = output['action']
            else:
                action = output

            actions.append(action)

            if return_internals:
                # Extract internal activations and hidden states
                internals = self._extract_internals(model, observation)
                all_internals.append(internals)

                # Extract latent representation from VLA
                if internals is not None and 'hidden_state' in internals:
                    hidden_states.append(internals['hidden_state'])

        # Stack actions: (B, K, action_dim) where K = ensemble_size
        actions = torch.stack(actions, dim=1)

        # Compute statistics
        action_mean = actions.mean(dim=1)  # (B, action_dim)
        action_var = actions.var(dim=1)    # (B, action_dim) - epistemic uncertainty

        result = {
            'action': action_mean,
            'action_var': action_var,
            'epistemic_uncertainty': action_var.mean(dim=-1),  # (B,) scalar
            'actions': actions,  # (B, ensemble_size, action_dim) - all ensemble actions
        }

        if return_internals:
            # Aggregate internals across ensemble
            if all_internals and all_internals[0] is not None:
                result['internals'] = self._aggregate_internals(all_internals)

            # Include hidden states for latent drift calculation
            if hidden_states:
                result['hidden_states'] = torch.stack(hidden_states, dim=1)  # (B, ensemble_size, hidden_dim)
                result['hidden_state_mean'] = result['hidden_states'].mean(dim=1)  # (B, hidden_dim)

        # Perturbation stability test: Run with augmented observation
        if return_internals:
            result['perturbed_actions'] = self._test_perturbation_stability(observation)

        return result

    def _extract_internals(self, model, observation):
        """Extract internal activations and hidden states from SmolVLA model"""
        try:
            internals = {}

            # SmolVLA architecture: Vision encoder ‚Üí Language model ‚Üí Action head
            # We hook into intermediate layers to extract representations

            # 1. Vision encoder hidden states
            if hasattr(model, 'model'):
                if hasattr(model.model, 'visual'):
                    # Get vision embeddings
                    visual = model.model.visual
                    if hasattr(visual, 'embeddings'):
                        internals['vision_embeddings'] = visual.embeddings

                # 2. Language model hidden states (core latent representation)
                if hasattr(model.model, 'transformer'):
                    transformer = model.model.transformer
                    # Try to access last hidden state from transformer
                    if hasattr(transformer, 'h'):  # Layers
                        # Get output of last transformer layer
                        last_layer = transformer.h[-1]
                        if hasattr(last_layer, 'output'):
                            hidden = last_layer.output
                            # Pool to fixed size representation
                            if isinstance(hidden, torch.Tensor):
                                # Mean pool over sequence: (B, seq_len, hidden_dim) ‚Üí (B, hidden_dim)
                                hidden_pooled = hidden.mean(dim=1) if hidden.dim() > 2 else hidden
                                internals['hidden_state'] = hidden_pooled

                # 3. Try direct access to model's internal state
                if hasattr(model, 'get_latent_state'):
                    internals['latent_state'] = model.get_latent_state()

                # Fallback: Use model's output layer input as hidden state
                if 'hidden_state' not in internals:
                    # Access the action head's input (last representation before action)
                    if hasattr(model, 'policy_head'):
                        # Hook will be set up separately if needed
                        pass

                    # Create pseudo hidden state from observation for now
                    # This is a fallback - real implementation would hook into model
                    if 'observation.state' in observation:
                        state = observation['observation.state']
                        # Use state as a proxy for hidden representation
                        internals['hidden_state'] = state  # (B, state_dim)

            return internals if internals else None
        except Exception as e:
            # If we can't extract internals, return None
            # But create minimal hidden state from observation
            try:
                if 'observation.state' in observation:
                    return {'hidden_state': observation['observation.state']}
            except:
                pass
            return None

    def _test_perturbation_stability(self, observation: Dict[str, torch.Tensor]) -> torch.Tensor:
        """
        Test model's sensitivity by running inference on perturbed observations.
        This measures if small input changes cause large action changes (instability signal).

        Returns:
            perturbed_actions: (B, n_perturbations, action_dim) actions on perturbed inputs
        """
        n_perturbations = 3  # Small number to avoid overhead
        perturbed_actions = []

        for _ in range(n_perturbations):
            # Create perturbed observation
            obs_perturbed = {}
            for key, value in observation.items():
                if isinstance(value, torch.Tensor):
                    if 'image' in key.lower():
                        # Add small Gaussian noise to image: N(0, 0.01)
                        noise = torch.randn_like(value) * 0.01
                        obs_perturbed[key] = value + noise
                    elif 'state' in key.lower():
                        # Add small noise to state: N(0, 0.005)
                        noise = torch.randn_like(value) * 0.005
                        obs_perturbed[key] = value + noise
                    else:
                        obs_perturbed[key] = value
                else:
                    obs_perturbed[key] = value

            # Run forward pass on perturbed input (use first model only for speed)
            with torch.no_grad():
                output = self.models[0].select_action(obs_perturbed)
                if isinstance(output, dict):
                    action = output['action']
                else:
                    action = output
                perturbed_actions.append(action)

        # Stack: (B, n_perturbations, action_dim)
        perturbed_actions = torch.stack(perturbed_actions, dim=1)
        return perturbed_actions

    def _aggregate_internals(self, all_internals):
        """Aggregate internal activations across ensemble"""
        if not all_internals or all_internals[0] is None:
            return None

        aggregated = {}

        # Get keys from first model
        keys = all_internals[0].keys()

        for key in keys:
            try:
                # Stack tensors from all models
                tensors = [internals[key] for internals in all_internals if key in internals]
                if tensors and all(t is not None for t in tensors):
                    stacked = torch.stack(tensors)
                    aggregated[f'{key}_mean'] = stacked.mean(dim=0)
                    aggregated[f'{key}_var'] = stacked.var(dim=0)
            except:
                continue

        return aggregated if aggregated else None


class SignalExtractor:
    """
    Extract 12D feature vector from VLA ensemble output.
    These signals are predictive of failures.
    """

    def __init__(self):
        # History buffer for trajectory features
        self.action_history = []
        self.max_history = 10  # Last 10 actions

    def extract(self, vla_output: Dict) -> torch.Tensor:
        """
        Extract 12D signal vector from VLA output.

        Signals (12 dimensions):
        1. Epistemic uncertainty (ensemble variance)
        2-3. Action magnitude and variance
        4-5. Action smoothness and trajectory divergence
        6-8. Per-joint variances (first 3 joints/dims)
        9-12. Rolling statistics (mean, std, min, max of recent uncertainty)

        Args:
            vla_output: Output dict from SmolVLAEnsemble.forward()

        Returns:
            signals: (B, 12) feature vector
        """

        batch_size = vla_output['action'].shape[0]
        action_dim = vla_output['action'].shape[1]
        signals = []

        # 1. Epistemic uncertainty (scalar)
        epistemic = vla_output['epistemic_uncertainty']  # (B,)
        signals.append(epistemic.unsqueeze(-1))

        # 2. Action magnitude
        action = vla_output['action']  # (B, action_dim)
        action_mag = torch.norm(action, dim=-1)
        signals.append(action_mag.unsqueeze(-1))

        # 3. Action variance (mean across dimensions)
        action_var = vla_output['action_var']  # (B, action_dim)
        action_var_mean = action_var.mean(dim=-1)
        signals.append(action_var_mean.unsqueeze(-1))

        # 4-5. Action smoothness and trajectory divergence
        if len(self.action_history) > 0:
            prev_action = self.action_history[-1]

            # Action smoothness (L2 norm of action difference)
            action_smoothness = torch.norm(action - prev_action, dim=-1)
            signals.append(action_smoothness.unsqueeze(-1))

            # Trajectory divergence (vs mean history)
            action_history_tensor = torch.stack(self.action_history)
            action_mean_history = action_history_tensor.mean(dim=0)
            traj_divergence = torch.norm(action - action_mean_history, dim=-1)
            signals.append(traj_divergence.unsqueeze(-1))
        else:
            # No history yet - use zeros
            signals.extend([torch.zeros(batch_size, 1, device=epistemic.device)] * 2)

        # Update history
        self.action_history.append(action.detach())
        if len(self.action_history) > self.max_history:
            self.action_history.pop(0)

        # 6-8. Per-joint/dimension variances (first 3)
        n_dims_to_track = min(3, action_dim)
        signals.append(action_var[:, :n_dims_to_track])  # (B, 3)

        # If action_dim < 3, pad with zeros
        if n_dims_to_track < 3:
            padding = torch.zeros(batch_size, 3 - n_dims_to_track, device=epistemic.device)
            signals[-1] = torch.cat([signals[-1], padding], dim=-1)

        # 9-12. Rolling statistics of uncertainty
        if len(self.action_history) >= 2:
            # Get uncertainty history
            uncertainty_history = []
            for _ in range(min(len(self.action_history), 5)):
                uncertainty_history.append(epistemic)  # Simplified - using current

            uncertainty_tensor = torch.stack(uncertainty_history)

            # Compute rolling statistics
            unc_mean = uncertainty_tensor.mean(dim=0)
            unc_std = uncertainty_tensor.std(dim=0)
            unc_min = uncertainty_tensor.min(dim=0)[0]
            unc_max = uncertainty_tensor.max(dim=0)[0]

            signals.extend([
                unc_mean.unsqueeze(-1),
                unc_std.unsqueeze(-1),
                unc_min.unsqueeze(-1),
                unc_max.unsqueeze(-1)
            ])
        else:
            # Not enough history - use current uncertainty
            signals.extend([epistemic.unsqueeze(-1)] * 4)

        # Concatenate all signals
        signals = torch.cat(signals, dim=-1)  # (B, 12)

        return signals

    def reset(self):
        """Reset history (call at episode start)"""
        self.action_history = []


class EnhancedSignalExtractor:
    """
    Enhanced signal extractor with 18D features from VLA internals.

    Signals (18 dimensions):
    [BASIC - 12D]
    1. Epistemic uncertainty (ensemble variance)
    2-3. Action magnitude and variance
    4-5. Action smoothness and trajectory divergence
    6-8. Per-joint variances (first 3 joints)
    9-12. Rolling statistics (mean, std, min, max of uncertainty)

    [STATE REPRESENTATION - 2D]
    13. Latent drift (change in VLA hidden state)
    14. OOD distance (out-of-distribution detection)

    [SENSITIVITY - 2D]
    15. Augmentation stability (variance across perturbed inputs)
    16. Perturbation sensitivity (max deviation under noise)

    [REALITY CHECK - 2D]
    17. Execution mismatch (predicted vs actual state change)
    18. Constraint margin (distance to joint/workspace limits)
    """

    def __init__(self, device='cuda:0'):
        # History buffers
        self.action_history = []
        self.hidden_state_history = []
        self.prev_state = None  # For execution mismatch
        self.prev_action = None
        self.max_history = 10
        self.device = torch.device(device)

        # OOD detection: Track running statistics of hidden states
        self.hidden_mean = None
        self.hidden_std = None
        self.n_samples = 0

    def extract(self, vla_output: Dict, robot_state: Optional[torch.Tensor] = None) -> torch.Tensor:
        """
        Extract 18D signal vector from VLA output and robot state.

        Args:
            vla_output: Output dict from SmolVLAEnsemble.forward() containing:
                - 'action': (B, action_dim)
                - 'action_var': (B, action_dim)
                - 'epistemic_uncertainty': (B,)
                - 'hidden_state_mean': (B, hidden_dim) - VLA latent representation
                - 'perturbed_actions': (B, n_pert, action_dim)
            robot_state: (B, state_dim) current robot state (joint positions, etc.)

        Returns:
            signals: (B, 18) feature vector
        """
        batch_size = vla_output['action'].shape[0]
        action_dim = vla_output['action'].shape[1]
        signals = []

        # ============================================================
        # BASIC SIGNALS (1-12): Original uncertainty signals
        # ============================================================

        # 1. Epistemic uncertainty
        epistemic = vla_output['epistemic_uncertainty']  # (B,)
        signals.append(epistemic.unsqueeze(-1))

        # 2. Action magnitude
        action = vla_output['action']
        action_mag = torch.norm(action, dim=-1)
        signals.append(action_mag.unsqueeze(-1))

        # 3. Action variance
        action_var = vla_output['action_var']
        action_var_mean = action_var.mean(dim=-1)
        signals.append(action_var_mean.unsqueeze(-1))

        # 4-5. Action smoothness and trajectory divergence
        if len(self.action_history) > 0:
            prev_action = self.action_history[-1]
            action_smoothness = torch.norm(action - prev_action, dim=-1)
            signals.append(action_smoothness.unsqueeze(-1))

            action_history_tensor = torch.stack(self.action_history)
            action_mean_history = action_history_tensor.mean(dim=0)
            traj_divergence = torch.norm(action - action_mean_history, dim=-1)
            signals.append(traj_divergence.unsqueeze(-1))
        else:
            signals.extend([torch.zeros(batch_size, 1, device=self.device)] * 2)

        self.action_history.append(action.detach())
        if len(self.action_history) > self.max_history:
            self.action_history.pop(0)

        # 6-8. Per-joint variances
        n_dims_to_track = min(3, action_dim)
        joint_vars = action_var[:, :n_dims_to_track]
        if n_dims_to_track < 3:
            padding = torch.zeros(batch_size, 3 - n_dims_to_track, device=self.device)
            joint_vars = torch.cat([joint_vars, padding], dim=-1)
        signals.append(joint_vars)

        # 9-12. Rolling statistics of uncertainty
        if len(self.action_history) >= 2:
            uncertainty_history = [epistemic for _ in range(min(len(self.action_history), 5))]
            uncertainty_tensor = torch.stack(uncertainty_history)
            unc_mean = uncertainty_tensor.mean(dim=0)
            unc_std = uncertainty_tensor.std(dim=0)
            unc_min = uncertainty_tensor.min(dim=0)[0]
            unc_max = uncertainty_tensor.max(dim=0)[0]
            signals.extend([
                unc_mean.unsqueeze(-1),
                unc_std.unsqueeze(-1),
                unc_min.unsqueeze(-1),
                unc_max.unsqueeze(-1)
            ])
        else:
            signals.extend([epistemic.unsqueeze(-1)] * 4)

        # ============================================================
        # STATE REPRESENTATION SIGNALS (13-14): VLA internals
        # ============================================================

        # 13. Latent drift: Change in VLA hidden state
        if 'hidden_state_mean' in vla_output:
            hidden_state = vla_output['hidden_state_mean']  # (B, hidden_dim)

            if len(self.hidden_state_history) > 0:
                prev_hidden = self.hidden_state_history[-1]
                latent_drift = torch.norm(hidden_state - prev_hidden, dim=-1)  # (B,)
            else:
                latent_drift = torch.zeros(batch_size, device=self.device)

            signals.append(latent_drift.unsqueeze(-1))

            # Update hidden state history
            self.hidden_state_history.append(hidden_state.detach())
            if len(self.hidden_state_history) > self.max_history:
                self.hidden_state_history.pop(0)

            # 14. OOD distance: Mahalanobis-like distance
            # Update running statistics
            if self.hidden_mean is None:
                self.hidden_mean = hidden_state.mean(dim=0).detach()
                self.hidden_std = torch.ones_like(self.hidden_mean) * 0.1
                self.n_samples = 1
            else:
                # Online update of mean and std
                alpha = min(0.01, 1.0 / (self.n_samples + 1))
                self.hidden_mean = (1 - alpha) * self.hidden_mean + alpha * hidden_state.mean(dim=0).detach()
                # Simplified std update
                self.hidden_std = (1 - alpha) * self.hidden_std + alpha * (hidden_state - self.hidden_mean).abs().mean(dim=0).detach()
                self.n_samples += 1

            # Compute normalized distance (OOD score)
            ood_distance = torch.norm((hidden_state - self.hidden_mean) / (self.hidden_std + 1e-6), dim=-1)
            signals.append(ood_distance.unsqueeze(-1))
        else:
            # No hidden state available - use zeros
            signals.extend([torch.zeros(batch_size, 1, device=self.device)] * 2)

        # ============================================================
        # SENSITIVITY SIGNALS (15-16): Perturbation response
        # ============================================================

        # 15-16. Augmentation stability: variance under perturbations
        if 'perturbed_actions' in vla_output:
            perturbed_actions = vla_output['perturbed_actions']  # (B, n_pert, action_dim)

            # Variance across perturbations
            aug_var = perturbed_actions.var(dim=1).mean(dim=-1)  # (B,)
            signals.append(aug_var.unsqueeze(-1))

            # Max deviation from nominal action
            deviation = (perturbed_actions - action.unsqueeze(1)).norm(dim=-1)  # (B, n_pert)
            max_deviation = deviation.max(dim=-1)[0]  # (B,)
            signals.append(max_deviation.unsqueeze(-1))
        else:
            # No perturbation data - use zeros
            signals.extend([torch.zeros(batch_size, 1, device=self.device)] * 2)

        # ============================================================
        # REALITY CHECK SIGNALS (17-18): Physical consistency
        # ============================================================

        # 17. Execution mismatch: predicted vs actual state change
        if robot_state is not None and self.prev_state is not None and self.prev_action is not None:
            # Actual state change
            actual_delta = robot_state - self.prev_state  # (B, state_dim)

            # Predicted state change (using action as proxy)
            # In reality, this would use a learned forward model
            # For now: assume action correlates with state change
            predicted_delta = self.prev_action[:, :robot_state.shape[1]]  # Match dimensions

            # Mismatch: L2 norm of difference
            execution_mismatch = torch.norm(actual_delta - predicted_delta, dim=-1)  # (B,)
            signals.append(execution_mismatch.unsqueeze(-1))
        else:
            signals.append(torch.zeros(batch_size, 1, device=self.device))

        # Update prev state/action
        if robot_state is not None:
            self.prev_state = robot_state.detach()
        self.prev_action = action.detach()

        # 18. Constraint margin: distance to joint/workspace limits
        if robot_state is not None:
            # Typical robot joint limits: [-œÄ, œÄ] or [-2.8, 2.8] for Franka
            # Compute distance to nearest limit
            joint_limits_lower = torch.tensor([-2.8, -1.76, -2.8, -3.07, -2.8, -0.017, -2.8],
                                             device=self.device)[:robot_state.shape[1]]
            joint_limits_upper = torch.tensor([2.8, 1.76, 2.8, -0.07, 2.8, 3.75, 2.8],
                                             device=self.device)[:robot_state.shape[1]]

            # Distance to lower limit
            dist_lower = robot_state - joint_limits_lower
            # Distance to upper limit
            dist_upper = joint_limits_upper - robot_state

            # Minimum distance to any limit (per joint)
            min_margin = torch.minimum(dist_lower, dist_upper).min(dim=-1)[0]  # (B,)

            # Clamp to [0, ‚àû) and invert (closer to limit = higher signal)
            constraint_signal = torch.clamp(-min_margin + 0.5, min=0.0)  # (B,)
            signals.append(constraint_signal.unsqueeze(-1))
        else:
            signals.append(torch.zeros(batch_size, 1, device=self.device))

        # ============================================================
        # Concatenate all signals: (B, 18)
        # ============================================================
        signals = torch.cat(signals, dim=-1)

        return signals

    def reset(self):
        """Reset all history buffers (call at episode start)"""
        self.action_history = []
        self.hidden_state_history = []
        self.prev_state = None
        self.prev_action = None


# Test script
if __name__ == "__main__":
    print("üß™ Testing SmolVLA Ensemble Wrapper...")
    print("=" * 60)

    # Check if CUDA is available
    if not torch.cuda.is_available():
        print("‚ùå CUDA not available! This system requires a GPU.")
        exit(1)

    print(f"‚úÖ CUDA available: {torch.cuda.get_device_name(0)}")
    print(f"   GPUs detected: {torch.cuda.device_count()}")
    print()

    # Initialize ensemble (using smaller ensemble for testing)
    try:
        vla = SmolVLAEnsemble(
            model_path="~/models/smolvla/smolvla_base",
            ensemble_size=2,  # Use 2 for testing (faster)
            device="cuda:0"
        )
        print("\n‚úÖ Ensemble initialized successfully!")
    except Exception as e:
        print(f"\n‚ùå Failed to initialize ensemble: {e}")
        exit(1)

    print("\nüìù Model Loading Test:")
    print("   ‚úÖ Successfully loaded 2√ó SmolVLA-450M models")
    print(f"   ‚úÖ Models on device: {vla.device}")
    print(f"   ‚úÖ Ensemble size: {vla.ensemble_size}")

    # Note about forward pass
    print("\n‚ö†Ô∏è  NOTE: SmolVLA requires properly formatted observations")
    print("   from a real environment (with camera images, state, and")
    print("   language tokens). Forward pass testing will be done")
    print("   during actual data collection with real observations.")

    print("\n" + "=" * 60)
    print("‚úÖ MODEL LOADING TEST PASSED!")
    print("=" * 60)
    print("\nüéâ SmolVLA ensemble is ready!")
    print("\nüìã Next steps:")
    print("   1. Set up simulation environment (MuJoCo or IsaacLab)")
    print("   2. Create data collection script")
    print("   3. Run data collection with real observations")
    print("\n‚ú® The VLA wrapper will work with real environment observations")




